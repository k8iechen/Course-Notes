## CHAPTER 1: SIGNALS & SYSTEMS

**Signal**: set of data/information

- Mostly functions of time, but applies to other independent variables

**Systems**: entity that processes a set of signals (inputs) to yield another set of signals (outputs)

- Can be hardware or software

### 1.1 Size of Signal

[Def] Number that indicates largeness/strength of entity

- Measure includes amplitude & duration

#### 1.1-1 Signal Energy

- must be finite for a meaningful measure of signal size
- necessary condition
  - $ amplitude\to 0 $ as $ |t|\to \infty $ , else Eq. (1) doesn't converge

Area under signal *x(t)* as a measure of signal size:

- accounts for amplitude & duration
- squared to ensure positive & negatives don't cancel

$$
E_x = \int_{-\infty}^\infty |x(t)|^2 dt \tag{1.1.1-1}
$$

simplifies for real-valued signal $x(t)$ to $ E_x = \int_{-\infty}^\infty x^2(t) dt \ $.

Notes:

- signal energy depends on signal AND load: 
  - energy dissipated in normalized load of 1 ohm resistor if voltage x(t) were applied across resistor
  - indicative of energy capacity of signal, not actual energy; thus conservation of energy doesn't apply

#### 1.1-2 Signal Power

- time average of the energy

When $ amplitude $ does NOT $ \to 0 $ as $ |t|\to \infty $ , signal energy is infinite. Thus signal power is a more meaningful measure, if it exists:
$$
P_x = \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} |x(t)|^2 dt\\ \tag{1.1.2-1}
$$
simplifies for real-valued signal $x(t)$ to $P_x = \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} x^2(t) dt\\$.

-  mean-square value of $|x(t)|$ 
- $\sqrt{P_x}$ is the root-mean-square value of $x(t)$

![image-20200510140028529](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200510140028529.png)

**Example**: Determining Power & RMS Values

a) sinusoid:	$ x(t) = C \cdot cos(w_{0}t+\theta) $

Sinusoid, with amplitude C. Period = $ T_{0} = 2\pi/w{0} $.
$$
\begin{align*}
P_x &= \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} C^2cos^2(w_{0}t+\theta) dt\\
&= \lim_{T\to\infty} \frac{C^2}{2T}\ \int_{-T/2}^{T/2} 1+cos^2(2w_{0}t+2\theta) dt \\
&= \lim_{T\to\infty} \frac{C^2}{2T}\ \int_{-T/2}^{T/2} dt + \lim_{T\to\infty} \frac{C^2}{2T}\ \int_{-T/2}^{T/2}cos^2(2w_{0}t+2\theta) dt \\
&= \frac{C^2}{2} + 0 \\
&= \frac{C^2}{2} \\
\end{align*} \\
$$
Note: $RMS = \frac{C}{\sqrt{2}}$ . While $ w_{0} \neq 0 $, frequency doesn't affect power. If $ w_{0}=0 $, $P_{x}=C^2$.

b) sinusoidal sum:	 $ x(t) = C_{1} \cdot cos(w_{1}t+\theta_{1}) + C_{2} \cdot cos(w_{2}t+\theta_{2})$,		 $w_{1} \neq w_{2} $
$$
\begin{align*}
P_x &= \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} [C_{1}cos(w_{1}t+\theta_{1})+C_{2}cos(w_{2}t+\theta_{2})]^2 dt\\
&= \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} C_{1}^2cos^2(w_{1}t+\theta_{1})\ dt + \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} C_{2}^2cos^2(w_{2}t+\theta_{2})\ dt \\
&+ \lim_{T\to\infty} \frac{2C_{1}C_{2}}{T}\ \int_{-T/2}^{T/2} cos(w_{1}t+\theta_{1})cos(w_{2}t+\theta_{2})\ dt \\
&= \frac{C_{1}^2}{2} + \frac{C_{2}^2}{2}\\
\end{align*} \\
$$
$RMS = \sqrt{(C_{1}^2 + C_{2}^2)/2}$

If $w_{1} = w_{2}$:
$$
\begin{align*}
P_{x} &= \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} [C_{1}cos(w_{1}t+\theta_{1})+C_{2}cos(w_{2}t+\theta_{2})]^2 dt\\
&= TBD\\
&= [C_{1}^2 + C_{2}^2 + 2C_{1}C_{2}cos(\theta_{1}-\theta_{2})]/2 \\

\end{align*}
$$
General Case: sum of any n sinusoids with distinct frequencies

$x(t) = C_{0} + \sum_{n=1}^\infty C_{n}cos(w_{n}t + \theta_{n})$

$P_{x} = C_{0}^2 + \frac{1}{2} \sum_{n=1}^\infty C_{n}^2$

c) complex:	 $ x(t) = D\cdot e^{jw_{0}t} $
$$
\begin{align*}
P_x &= \lim_{T\to\infty} \frac{1}{T}\ \int_{-T/2}^{T/2} |De^{iw_{0}t}|^2 dt\\
&= |D|^2
\end{align*}
$$
$RMS = |D| $

### 1.2 Signal Operations

#### 1.2-1 Time Shifting

$\exists \phi$ s.t. signals in $\phi(t)$ are a T second delay of $x(t)$. Thus $\phi{(t+T)} = x(t)$ and $\phi{(t)} = x(t-T)$.

#### 1.2-2 Time Scaling

$\exists \phi$ s.t. signals in $\phi(t)$ are compressed by factors of $a$ w.r.t. $x(t)$. Thus $\phi{(\frac{t}{2})} = x(t)$ and $\phi{(t)} = x(2t)$.

#### 1.2-3 Time Reversal

$\exists \phi$  s.t. signals in $\phi(t)$ are reflections of $x(t)$ across the vertical axis. Thus $\phi{(t)} = x(-t)$.

### 1.3 Classification of Signals

##### 1.3-1 Continuous-Time & Discrete-Time 

signal specified for a continuum of values versus signal specified for discrete values

- nature of signal along time

##### 1.3-2 Analog & Digital

- nature of signal along amplitude

**analog signal**: signal whose amplitude can take on any value in continuous range (amplitude can take on infinite values)

**digital signal**: signal whose amplitude takes on only a finite number of values

##### 1.3-3 Periodic & Aperiodic

Signal $x(t)$ is periodic if for some positive constant $T_{0}$, $x(t) = x(t+T_{0})\ \forall\ T$ .  
$$
\int_{a}^{a+T_{0}}\ x(t)\ dt = \int_{b}^{b+T_{0}}\ x(t)\ dt
$$
**everlasting signal**: $-\infty < t < \infty$. True everlasting signals cannot be generated in practice.

**causal signal**: $x(t)=0, t<0$

**anti-causal signal**: $x(t)=0\ \forall\ t \geq 0$

![image-20200515155349286](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200515155349286.png)

Else, aperiodic.

##### 1.3-4 Energy & Power

- cannot be both energy and power, but can be neither

**energy signal**: signal with finite energy

**power signal**: signal with finite, non-zero power (infinite energy); power is time average of energy (over an infinitely large [time] interval, else will not approach limit)

**ramp signal**: neither energy nor power signal.

$e^{-at}$ is neither energy nor power signal for any $a \in \mathbb{R}$. However, if $a \notin \mathbb{R}$, it's a power signal with $P_{x} = 1$ regardless of the value of $a$.

##### 1.3-5 Deterministic & Probabilistic

**deterministic signal**: a signal whose physical description is known completely in math/graphical form

**random signal**: a signal whose values cannot be predicted precisely but are known only in terms of probabilistic description (beyond scope of BME252)

### 1.4 Useful Signal Models

##### 1.4-1 Unit Step Function $u(t)$

$$
u(t) = 
\begin{cases}
1	&{t \geq 0} \\
0	&{t < 0} \\
\end{cases} 	\tag{1.4.1-1}
$$

Multiply by $u(t)$ to obtain a signal that starts at $t = 0$. 

##### 1.4-2 Unit Impulse Function $\delta(t)$

Dirac Delta:
$$
\delta(t)=0,\ t\neq0,\ \int_{-\infty}^{\infty}\delta(t)\ dt=1 	\tag{1.4.2-1}
$$

Rectangular Pulse: width $\epsilon \to 0$, height $1/\epsilon \to \infty$. Undefined at $t = 0$.

e.g. 1.20(a)	 $ae^{-at}u(t)$

![image-20200516135458625](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200516135458625.png)

as $a\to\infty$, pulse height $\to \infty$, width/duration $\to\infty$. Yet area under curve is unity regardless of the value of $a$ because
$$
\int_{0}^{\infty}\ ae^{-at}dt=1
$$
Exact pulse function cannot be generated in practice, only approached. From 1.4-2, impulse function $k\delta(t)=0\ \forall\ t\neq0$ has area $k$. 

###### Multiplication of a Function by an Impulse

$\exists \phi(t)$ s.t. it's continuous at $t=0$. Since impulse has non-zero value only at $t=0$, and the value of $\phi(t)$ at $t=0$ is $\phi(0)$:
$$
\phi(t)\delta(t)=\phi(0)\delta(t)
$$
Result: an impulse @ $t=0$, has strength $\phi(0)$.

Generalization:
$$
\phi(t)\delta(t-T)=\phi(T)\delta(t-T) 	\tag{1.4.2-2}
$$

###### Sampling Property of Unit Impulse Function

$$
\int_{-\infty}^\infty\ \phi(t)\delta(t-T)=\phi(T)\int_{-\infty}^\infty\ \delta(t)\ dt = \phi(T) 	\tag{1.4.2-3}
$$

*area under the product of a function with impulse $\delta(t-T)$ is equal to the value of that function at the instant at which the unit impulse is located

###### Unit Impulse as  Generalized Function

**generalized function**: defined by its effect on other functions instead of by its value at every instant of time

Impulse function is defined in terms of its effects on test function $\phi(t)$.

Unit impulse function: a function for which the area under its product with a function $\phi(t)$ is equal to the value of function $\phi(t)$ in the instant at which the impulse is located

- assumes $\phi(t)$ is continuous at location of impulse

$$
\begin{align*}
\int_{-\infty}^\infty\ \frac{du(t)}{dt}\phi(t)dt
&= u(t)\phi(t)|_{-\infty}^{\infty} - \int_{-\infty}^{\infty}u(t)\dot\phi(t)dt \\
&= \phi(\infty)-0-\int_{0}^{\infty}\dot\phi(t)dt \\
&= \phi(\infty)-\phi(t)|_{0}^{\infty} \\
&=\phi(0) \\
\frac{du(t)}{dt}&=\delta(t) 	\tag{1.4.2-4} \\
\int_{-\infty}^{t}\delta(\tau)d\tau &= u(t)
\end{align*} \\
$$

##### 1.4-3 Exponential Function $e^{st}$

$\exists$ complex number $s$ s.t. $s = \sigma + jw$, therefore
$$
e^{st}=e^{(\sigma+jw)t}=e^{\sigma t}e^{jwt}=e^{\sigma t}(cos(wt)+j\sin(wt))
$$
Since $s^* = \sigma - jw$, then
$$
e^{s^*t}=e^{(\sigma-jw)t}=e^{\sigma t}e^{-jwt}=e^{\sigma t}(cos(wt)-j\sin(wt))
$$
and
$$
e^{\sigma t} \cos{wt}= \frac{1}{2}(e^{st}+e^{s^*t}) 	\tag{1.4.3-1}
$$
[Euler's formula] $e^{st}$ is a generalization of $e^{jwt}$, where frequency variable jw is generalized to complex variable $s=\sigma + jw$. Class of functions expressed in terms of $e^{st}$:

| Classes                        | Functions              | Conditions           |
| ------------------------------ | ---------------------- | -------------------- |
| Constant                       | $k=ke^{0t}$            | $s=0$                |
| Monotonic Exponential          | $e^{\sigma t}$         | $w=0,s=\sigma$       |
| Sinusoid                       | $\cos{wt}$             | $\sigma=0, s=\pm jw$ |
| Exponentially Varying Sinusoid | $e^{\sigma t}\cos{wt}$ | $s=\sigma \pm jw$    |

![image-20200519165711150](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200519165711150.png)

About $e^{st}$:

​	w: frequency of oscillation

​	$\sigma$: rate of increase/decrease of amplitude

Signals' complex frequencies lie on **real** axis ($\sigma$ axis, where $w=0$). 

If signals' frequencies lie on **imaginary** axis ($w$ axis, where $\sigma=0$), $e^{\sigma t}=1$. Signals are conventional sinusoids with constant amplitude.

![image-20200519170530130](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200519170530130.png)

### 1.5 Even & Odd Functions

[def] even function $X_{e}$: symmetrical about vertical axis

[def] odd function $X_{o}$: antisymmetrical about vertical axis
$$
X_{e}(t) = X_{e}(-t) \\
X_{o}(t) = -X_{o}(-t) \\
$$

##### 1.5-1 Properties of Even & Odd Functions

$$
X_{e} \times X_{o} = X_{o}' \\
X_{o} \times X_{o} = X_{e} \\
X_{e} \times X_{e} = X_{e}' \\
$$

Area:
$$
\int_{-a}^{a} X_{e}(t)dt = 2 \int_{0}^{a}X_{e}(t)dt \\
\int_{-a}^{a}X_{o}(t)dt = 0 \\
$$
*every signal can be expressed as a sum of even & odd functions

###### Modification for Complex Signals

- can be decomposed into even & odd components OR conjugate symmetries

- conjugate symmetric if $x_{cs}(t)=x^*(-t)$

  Real part is even, imaginary part is odd, thus even signal

- conjugate-antisymmetric if $x_{ca}(t)=-x^*(-t)$

  Real part is odd, imaginary part is even, thus odd signal

$$
x(t) = x_{cs}(t) + x_{ca}(t)\ \text{where} \\
x_{cs}(t)=\frac{x(t)+x^*(-t)}{2} \\
x_{ca}(t)=\frac{x(t)-x^*(-t)}{2} \\
$$

### 1.6 Systems

Study of systems consists of mathematical modeling, analysis design. 

Consider RC circuit with current source $x(t)$ as input. Output is given by:
$$
\begin{align*}
y(t)&=Rx(t)+\frac{1}{C}\int_{-\infty}^{t}x(\tau) d\tau \\
&= Rx(t)+\frac{1}{C}\int_{-\infty}^{0}x(\tau) d\tau +\frac{1}{C}\int_{0}^{t}x(\tau) d\tau \\
&=Rx(t)+v_{C}(0)+\frac{1}{C}\int_{0}^{t}\ x(\tau) d\tau\ &t\geq 0 \\
\end{align*}
$$
Generalized form*:
$$
\begin{align*}
y(t)&=v_{C}(t_0)+Rx(t)+\frac{1}{C}\int_{t_0}^{t}\ x(\tau) d\tau\ &t\geq t_0\tag{1.6-1}
\end{align*}
$$
*$v_C(t_0)$ is initial capacitator voltage

![image-20200523134045088](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200523134045088.png)

### 1.7 Classification of Systems

Categories of systems*:

1. linear & nonlinear
2. constant-parameter & time-varying-parameter
3. instantaneous (memoryless) & dynamic
4. causal & noncausal
5. continuous-time & discrete-time
6. analog & digital
7. invertible & non-invertible
8. stable & unstable

*other classifications, such as deterministic & probabilistic, are not in this course

##### 1.7-1 Linear & Nonlinear Systems

superposition property:

- additivity property:
  $$
  x_1\to y_1\and x_2\to y_2 \implies x_1+x_2\to y_1+y_2
  $$

- homogeneity (scaling property):
  $$
  \text{if } x\to y, \text{then }\forall\ \text{real and imaginary }k, kx\to ky
  $$

Thus,
$$
x_1\to y_1\and x_2\to y_2 \implies k_1x_1+k_2x_2\to k_1y_1+k_2y_2\ \forall\ k_1, k_2 \tag{1.7-1}
$$

###### Response of a Linear System

context: **single input, single output** (SISO) systems

linear system output for $t\geq 0$:

- results from 2 independent causes:
  - initial conditions of system (system state) at $t=0$
  - input $x(t)$ for $t\geq 0$
- must be sum of 2 components:
  - zero-input response (ZIR) resulting from initial response at $t=0$ with input $x(t)=0$ for $t\geq 0$.
  - zero-state response (ZSR) resulting from input $x(t)$ for $t\geq 0$ when initial conditions are assumed to be 0.
- both ZIR & ZSR must obey superposition w.r.t. their causes

Linear System Response:
$$
\text{total response = ZIR + ZSR} \tag{1.7-2}
$$
**decomposition property**: permits separation of an output into components resulting from initial conditions & from the input
$$
y(t)=\underbrace{v_{C}(t_0)}_{ZIR}+\underbrace{Rx(t)+\frac{1}{C}\int_{t_0}^{t}\ x(\tau) d\tau}_{ZSR}
$$

##### 1.7-2 Time-Invariant & Time-Varying Systems

**time-invariant**: constant parameter

time invariance property:

![image-20200523151226133](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200523151226133.png)

##### 1.7-3 Instantaneous & Dynamic Systems

A system is **instantaneous** if its output at any t depends, at most, on the strength of its inputs at same instant t.

*derivatives are NOT instantaneous: slope cannot be determined from a single point. Infinitesimally small memory must exist; see fundamental theorem of calculus.

##### 17-4 Causal & Noncausal Systems

**causal**: output at any instant $t_0$ depends only on value of input $x(t) \text{ for }t\leq t_0$.

*noncausal systems 

- are realizable when independent variable is not time (e.g. space)
- are realizable with time delay
- provides upper bound performance for causal systems

##### 1.7-5 Continuous-Time & Discrete-Time Systems

**continuous-time signals**: signals defined over a continuous range of time

![image-20200523153606031](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200523153606031.png)

##### 1.7-6 Analog & Digital Systems

e.g. digital computer => digital & discrete system

##### 1.7-7 Invertible & Noninvertible Systems

![image-20200523154013911](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200523154013911.png)

e.g. noninvertable: $y(t)=|x(t)|$, $y(t)=tx(t)$

##### 1.7-8 Stable & Unstable Systems

**External Stability**: every bounded input applied at input terminal results in a bounded output (BIBO: bounded-input/bounded-output)

### 1.8 System Model: Input-Output Description

system varieties: electrical, mechanical, hydraulic, acoustic, electromechanical, chemical, social, political, economic, biological, etc.

##### 1.8-1 Electrical Systems

e.g. Series RLC circuit

![image-20200523155215304](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200523155215304.png)

Kirchhoff's voltage law around loop: 
$$
v_L(t)+v_R(t)+v_C(t)=x(t) \\
v_L(t)+Ri(t)+\frac{1}{C}\int_{-\infty}^ti(\tau)d\tau=x(t) \\
\frac{dy(t)}{dt}+3y(t)+2\int_{-\infty}^ty(\tau)d\tau=x(t) \\
$$
Differentiating both sides:
$$
\frac{d^2y(t)}{dt^2}+3\frac{dy(t)}{dt}+2y(t)=\frac{dx(t)}{dt} \tag{1.8.1-1} \\
$$
Expressed using compact notation:
$$
\frac{dy(t)}{dt}\equiv Dy(t),\ \frac{d^2y(t)}{dt^2}\equiv D^2y(t),\ ...,\ \frac{d^Ny(t)}{dt^N}\equiv D^Ny(t) \\
$$

$$
(D^2+3D+2)y(t)=Dx(t) \tag{1.8.1-2} \\
$$

Integral operator expressed as inverse of differential operator:
$$
\int_{-\infty}^ty(\tau)d\tau\equiv\frac{1}{D}y(t) \\
\frac{d}{dt}\left[\int_{-\infty}^ty(\tau)d\tau\right]=y(t) \\
$$

##### 1.8-2 Mechanical Systems

planer motion => translational (rectilinear) motion & rotational (torsional) motion

###### Translational Systems

basic elements: ideal masses, linear springs, dashpots (viscous damping)

![image-20200524090416527](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200524090416527.png)

Newton's law of motion (a):
$$
x(t)=M\ddot y(t)=M\frac{d^2y(t)}{dt^2}=MD^2y(t)
$$
Linear spring (K is stiffness) (b):
$$
x(t)=Ky(t)
$$
Linear Dashpot (B is damping coefficient) (c):
$$
x(t)=B\dot y(t)=B\frac{dy(t)}{dt}=BDy(t)
$$

###### Rotational Systems

motion about an axis; variables:

- torque
- angular position
- angular velocity
- angular acceleration
- torsional springs
- torsional dashpots

$$
\begin{align*}
torque&=J\ddot\theta(t)=J\frac{d^2\theta(t)}{dt^2}=JD^2\theta(t)=JD^2\theta(t) \\
&= K\theta(t)
B\dot\theta(t)=BD\theta(t)
\end{align*}
$$

##### 1.8-3 Electromechanical Systems

![image-20200524091306930](C:\Users\Kaycee\AppData\Roaming\Typora\typora-user-images\image-20200524091306930.png)
$$
\begin{align*}
J\ddot\theta(t)&=\tau(t)-B\dot\theta(t) \\
(JD^2+BD)\theta(t)&=\tau(t) \\
(JD^2+BD)\theta(t)&=K_Tx(t) \\
J\frac{d^2\theta(t)}{dt^2}+B\frac{d\theta(t)}{dt}&=K_Tx(t) \tag{1.8.3-1} \\
\end{align*}
$$